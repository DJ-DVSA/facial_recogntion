{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 10:49:43.517438: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-19 10:49:43.562750: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 10:49:43.855770: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-19 10:49:43.857909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 10:49:45.115909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pth = '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for directories with more than 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 200000\n",
    "\n",
    "x = 10\n",
    "\n",
    "x+=1\n",
    "100 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "### List directories with more than 1 image\n",
    "im_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}\n",
    "\n",
    "## Function to walk through directories and count paths\n",
    "\n",
    "def list_directories_multiple_images(topDir: str, extensions: Union[list, tuple]) -> list:\n",
    "    \"\"\"Function to look through subdirectories to get thsoe containing multiple images\n",
    "\n",
    "    Args:\n",
    "        topDir (str): _description_\n",
    "        extensions (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        list: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = []\n",
    "    cnt = 0\n",
    "    # loop through directories\n",
    "    for root, dir, files in os.walk(topDir):\n",
    "        \n",
    "        cnt+= 1\n",
    "        # if 100 % cnt > 0:\n",
    "        #     print(\"Count = \", cnt)\n",
    "        \n",
    "        image_files = [f for f in files if Path(f).suffix.lower() in extensions]\n",
    "        if len(image_files) > 1:\n",
    "            paths.append(root)\n",
    "    \n",
    "    return(paths)\n",
    "    \n",
    "    \n",
    "multi_image_dirs = list_directories_multiple_images('/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/', im_extensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with first image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Ricky_Barnes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(multi_image_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [os.path.join(os.path.abspath(multi_image_dirs[50]), file) for file in os.listdir(multi_image_dirs[50] ) if file.lower().endswith(tuple(im_extensions))]\n",
    "\n",
    "image_files2 = [os.path.join(os.path.abspath(multi_image_dirs[51]), file) for file in os.listdir(multi_image_dirs[51] ) if file.lower().endswith(tuple(im_extensions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img_bgr = cv2.imread(image_files[0], cv2.IMREAD_COLOR)\n",
    "\n",
    "# #result = DeepFace.extract_faces(img_bgr)\n",
    "\n",
    "# type(img_bgr)\n",
    "\n",
    "# #plt.pcolor(img_bgr[:, :, 2])\n",
    "# cv2.imshow('Image',img_bgr)\n",
    "\n",
    "# # Wait indefinitely for a key press  \n",
    "# cv2.waitKey(0)\n",
    "# #  00\n",
    "# # # Destroy all the window\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verfiy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.22019959979611936,\n",
       " 'threshold': 0.3,\n",
       " 'model': 'Facenet512',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 63,\n",
       "   'y': 64,\n",
       "   'w': 127,\n",
       "   'h': 127,\n",
       "   'left_eye': (149, 111),\n",
       "   'right_eye': (96, 113)},\n",
       "  'img2': {'x': 71,\n",
       "   'y': 73,\n",
       "   'w': 112,\n",
       "   'h': 112,\n",
       "   'left_eye': (148, 114),\n",
       "   'right_eye': (101, 114)}},\n",
       " 'time': 1.47}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = DeepFace.verify(\n",
    "    img1_path=image_files[0],\n",
    "    img2_path=image_files[1], model_name=\"Facenet512\"\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:09<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "objs = DeepFace.analyze(\n",
    "  img_path = image_files[1], \n",
    "  actions = ['age', 'gender', 'race', 'emotion'],\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of all the races, ages, genders and emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1001%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Antonio_Trillanes',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Priscilla_Owen',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Jim_Tressel',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Ed_Smart',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Bill_Clinton',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Isabella_Rossellini',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Kim_Dae-jung',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Martha_Beatriz_Roque',\n",
       " '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Fernando_Gonzalez']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_image_dirs[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features = pd.DataFrame(columns=['Name', 'Age', 'Gender', 'Race', 'Emotion', 'face confidence'])\n",
    "\n",
    "# Loop through the directories\n",
    "for cnt, idx in enumerate(multi_image_dirs[1001:1500]):\n",
    "    \n",
    "    #if cnt%10 == 0:\n",
    "    print(f\"Directory {1000 + cnt} of {len(multi_image_dirs)}\")\n",
    "    # get images in directory\n",
    "    t_image_files = [os.path.join(os.path.abspath(idx), file) for file in os.listdir(idx ) if file.lower().endswith(tuple(im_extensions))]\n",
    "    # loop through images in directory\n",
    "    for iidx in t_image_files[0:max(len(t_image_files), 3)]:\n",
    "        try:\n",
    "            objs = DeepFace.analyze(\n",
    "            img_path = iidx, \n",
    "            actions = ['age', 'gender', 'race', 'emotion'],\n",
    "            )\n",
    "        \n",
    "        \n",
    "            im_features.loc[len(im_features)] = [os.path.basename(iidx), objs[0]['age'], objs[0]['dominant_gender'],\n",
    "                                             objs[0]['dominant_race'], objs[0]['dominant_emotion'], objs[0]['face_confidence']]\n",
    "        except:\n",
    "            im_features.loc[len(im_features)] = [os.path.basename(iidx), 'No Face Detected', '', '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im_features3 = im_features\n",
    "\n",
    "im_features3.to_csv(\"/mnt/c/Users/Davidj/OneDrive - Driver and Vehicle Standards Agency/Documents/Projects/Discovery/Driving test facial Recognition/Main Discovery/deepface_test/face_classifications_csvs/lfw_class3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(im_features2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>face confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert_Kocharian_0004.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert_Kocharian_0001.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert_Kocharian_0002.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert_Kocharian_0003.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert_Kocharian_0005.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>Man</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>Paul_Bremer_0004.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>Paul_Bremer_0003.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>Paul_Bremer_0018.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>Morgan_Freeman_0001.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>Man</td>\n",
       "      <td>black</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>Morgan_Freeman_0002.jpg</td>\n",
       "      <td>27</td>\n",
       "      <td>Man</td>\n",
       "      <td>black</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2814 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Age Gender            Race  Emotion  \\\n",
       "0     Robert_Kocharian_0004.jpg  25    Man           white  neutral   \n",
       "1     Robert_Kocharian_0001.jpg  30    Man  middle eastern  neutral   \n",
       "2     Robert_Kocharian_0002.jpg  26    Man           white     fear   \n",
       "3     Robert_Kocharian_0003.jpg  30    Man  middle eastern    happy   \n",
       "4     Robert_Kocharian_0005.jpg  34    Man  middle eastern    happy   \n",
       "...                         ...  ..    ...             ...      ...   \n",
       "2809       Paul_Bremer_0004.jpg  38    Man           white  neutral   \n",
       "2810       Paul_Bremer_0003.jpg  34    Man           white  neutral   \n",
       "2811       Paul_Bremer_0018.jpg  37    Man           white     fear   \n",
       "2812    Morgan_Freeman_0001.jpg  37    Man           black  neutral   \n",
       "2813    Morgan_Freeman_0002.jpg  27    Man           black     fear   \n",
       "\n",
       "     face confidence  \n",
       "0               0.96  \n",
       "1               0.94  \n",
       "2               0.99  \n",
       "3               0.91  \n",
       "4               0.95  \n",
       "...              ...  \n",
       "2809            0.89  \n",
       "2810             0.9  \n",
       "2811            0.88  \n",
       "2812            0.94  \n",
       "2813            0.94  \n",
       "\n",
       "[2814 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 27,\n",
       "  'region': {'x': 55,\n",
       "   'y': 55,\n",
       "   'w': 148,\n",
       "   'h': 148,\n",
       "   'left_eye': (168, 108),\n",
       "   'right_eye': (88, 118)},\n",
       "  'face_confidence': 0.94,\n",
       "  'gender': {'Woman': 0.7658638060092926, 'Man': 99.234139919281},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': 0.08183773418444207,\n",
       "   'indian': 0.03439231778235796,\n",
       "   'black': 99.84802601909948,\n",
       "   'white': 0.001035973796922151,\n",
       "   'middle eastern': 0.00035856282647505104,\n",
       "   'latino hispanic': 0.03435206426965466},\n",
       "  'dominant_race': 'black',\n",
       "  'emotion': {'angry': 0.1254534930922091,\n",
       "   'disgust': 1.7913778238565214e-07,\n",
       "   'fear': 61.43893599510193,\n",
       "   'happy': 0.0007358773473242763,\n",
       "   'sad': 23.985520005226135,\n",
       "   'surprise': 0.00022976000764174387,\n",
       "   'neutral': 14.449124038219452},\n",
       "  'dominant_emotion': 'fear'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial_recognition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
