{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 09:45:34.505133: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-16 09:45:34.580933: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 09:45:35.342860: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-16 09:45:35.346832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 09:45:36.986758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pth = '/home/dave/discovery_projects/driving_test_impersonation/lfw_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for directories with more than 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 200000\n",
    "\n",
    "x = 10\n",
    "\n",
    "x+=1\n",
    "100 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "### List directories with more than 1 image\n",
    "im_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}\n",
    "\n",
    "## Function to walk through directories and count paths\n",
    "\n",
    "def list_directories_multiple_images(topDir: str, extensions: Union[list, tuple]) -> list:\n",
    "    \"\"\"Function to look through subdirectories to get thsoe containing multiple images\n",
    "\n",
    "    Args:\n",
    "        topDir (str): _description_\n",
    "        extensions (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        list: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = []\n",
    "    cnt = 0\n",
    "    # loop through directories\n",
    "    for root, dir, files in os.walk(topDir):\n",
    "        \n",
    "        cnt+= 1\n",
    "        # if 100 % cnt > 0:\n",
    "        #     print(\"Count = \", cnt)\n",
    "        \n",
    "        image_files = [f for f in files if Path(f).suffix.lower() in extensions]\n",
    "        if len(image_files) > 1:\n",
    "            paths.append(root)\n",
    "    \n",
    "    return(paths)\n",
    "    \n",
    "    \n",
    "multi_image_dirs = list_directories_multiple_images('/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/', im_extensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with first image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dave/discovery_projects/driving_test_impersonation/lfw_images/lfw-deepfunneled/lfw-deepfunneled/Ricky_Barnes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(multi_image_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [os.path.join(os.path.abspath(multi_image_dirs[50]), file) for file in os.listdir(multi_image_dirs[50] ) if file.lower().endswith(tuple(im_extensions))]\n",
    "\n",
    "image_files2 = [os.path.join(os.path.abspath(multi_image_dirs[51]), file) for file in os.listdir(multi_image_dirs[51] ) if file.lower().endswith(tuple(im_extensions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_bgr = cv2.imread(image_files[0], cv2.IMREAD_COLOR)\n",
    "\n",
    "#result = DeepFace.extract_faces(img_bgr)\n",
    "\n",
    "type(img_bgr)\n",
    "\n",
    "#plt.pcolor(img_bgr[:, :, 2])\n",
    "cv2.imshow('Image',img_bgr)\n",
    "\n",
    "# Wait indefinitely for a key press\n",
    "cv2.waitKey(0)\n",
    "#  00\n",
    "# # Destroy all the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verfiy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DeepFace.verify(\n",
    "    img1_path=image_files[0],\n",
    "    img2_path=image_files2[1], model_name=\"Facenet512\"\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "objs = DeepFace.analyze(\n",
    "  img_path = image_files[1], \n",
    "  actions = ['age', 'gender', 'race', 'emotion'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of all the races, ages, genders and emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1001%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 0 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 1 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.86it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.73it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 2 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 3 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.27it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.24it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.38it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 4 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.71it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.11it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 5 of 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.44it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.32it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.99it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.85it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.22it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.00it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.17it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.01it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.69it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  5.14it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.49it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.74it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.97it/s]\n",
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:00,  3.87it/s]"
     ]
    }
   ],
   "source": [
    "im_features = pd.DataFrame(columns=['Name', 'Age', 'Gender', 'Race', 'Emotion', 'face confidence'])\n",
    "\n",
    "# Loop through the directories\n",
    "for cnt, idx in enumerate(multi_image_dirs):\n",
    "    \n",
    "    if ~cnt%10:\n",
    "        print(f\"Directory {cnt} of {len(multi_image_dirs)}\")\n",
    "    # get images in directory\n",
    "    t_image_files = [os.path.join(os.path.abspath(idx), file) for file in os.listdir(idx ) if file.lower().endswith(tuple(im_extensions))]\n",
    "    # loop through images in directory\n",
    "    for iidx in t_image_files:\n",
    "        try:\n",
    "            objs = DeepFace.analyze(\n",
    "            img_path = iidx, \n",
    "            actions = ['age', 'gender', 'race', 'emotion'],\n",
    "            )\n",
    "        \n",
    "        \n",
    "            im_features.loc[len(im_features)] = [os.path.basename(iidx), objs[0]['age'], objs[0]['dominant_gender'],\n",
    "                                             objs[0]['dominant_race'], objs[0]['dominant_emotion'], objs[0]['face_confidence']]\n",
    "        except:\n",
    "            im_features.loc[len(im_features)] = [os.path.basename(iidx), 'No Face Detected', '', '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im_features.loc[len(im_features)] = [os.path.basename(iidx), 'No Face Detected', '', '', '', '']\n",
    "\n",
    "try:\n",
    "    objs = DeepFace.analyze(\n",
    "    img_path = iidx, \n",
    "    actions = ['age', 'gender', 'race', 'emotion'],\n",
    "    )\n",
    "        \n",
    "        \n",
    "    im_features.loc[len(im_features)] = [os.path.basename(iidx), objs[0]['age'], objs[0]['dominant_gender'],\n",
    "                                        objs[0]['dominant_race'], objs[0]['dominant_emotion'], objs[0]['face_confidence']]\n",
    "except:\n",
    "    im_features.loc[len(im_features)] = [os.path.basename(iidx), 'No Face Detected', '', '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>face confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ricky_Barnes_0001.jpg</td>\n",
       "      <td>27</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ricky_Barnes_0002.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonio_Trillanes_0002.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>Man</td>\n",
       "      <td>black</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antonio_Trillanes_0001.jpg</td>\n",
       "      <td>32</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antonio_Trillanes_0003.jpg</td>\n",
       "      <td>22</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Priscilla_Owen_0002.jpg</td>\n",
       "      <td>39</td>\n",
       "      <td>Woman</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Priscilla_Owen_0001.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>Woman</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jim_Tressel_0001.jpg</td>\n",
       "      <td>32</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jim_Tressel_0004.jpg</td>\n",
       "      <td>41</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jim_Tressel_0003.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jim_Tressel_0002.jpg</td>\n",
       "      <td>41</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ed_Smart_0003.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ed_Smart_0002.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ed_Smart_0001.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bill_Clinton_0002.jpg</td>\n",
       "      <td>32</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bill_Clinton_0020.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bill_Clinton_0012.jpg</td>\n",
       "      <td>No Face Detected</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name               Age Gender            Race  \\\n",
       "0        Ricky_Barnes_0001.jpg                27    Man           white   \n",
       "1        Ricky_Barnes_0002.jpg                28    Man           white   \n",
       "2   Antonio_Trillanes_0002.jpg                28    Man           black   \n",
       "3   Antonio_Trillanes_0001.jpg                32    Man           asian   \n",
       "4   Antonio_Trillanes_0003.jpg                22    Man           asian   \n",
       "5      Priscilla_Owen_0002.jpg                39  Woman           white   \n",
       "6      Priscilla_Owen_0001.jpg                35  Woman           white   \n",
       "7         Jim_Tressel_0001.jpg                32    Man           white   \n",
       "8         Jim_Tressel_0004.jpg                41    Man           white   \n",
       "9         Jim_Tressel_0003.jpg                35    Man           white   \n",
       "10        Jim_Tressel_0002.jpg                41    Man           white   \n",
       "11           Ed_Smart_0003.jpg                34    Man           white   \n",
       "12           Ed_Smart_0002.jpg                35    Man           white   \n",
       "13           Ed_Smart_0001.jpg                26    Man  middle eastern   \n",
       "14       Bill_Clinton_0002.jpg                32    Man           white   \n",
       "15       Bill_Clinton_0020.jpg                35    Man           white   \n",
       "16       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "17       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "18       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "19       Bill_Clinton_0012.jpg                35    Man           white   \n",
       "20       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "21       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "22       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "23       Bill_Clinton_0012.jpg  No Face Detected                          \n",
       "\n",
       "     Emotion face confidence  \n",
       "0      happy            0.93  \n",
       "1        sad            0.94  \n",
       "2   surprise            0.91  \n",
       "3       fear            0.92  \n",
       "4        sad            0.93  \n",
       "5      happy            0.91  \n",
       "6    neutral            0.88  \n",
       "7      happy            0.91  \n",
       "8      happy            0.93  \n",
       "9    neutral            0.91  \n",
       "10     angry            0.91  \n",
       "11     happy            0.94  \n",
       "12     happy            0.93  \n",
       "13     happy             0.9  \n",
       "14     happy            0.93  \n",
       "15       sad            0.94  \n",
       "16                            \n",
       "17                            \n",
       "18                            \n",
       "19       sad            0.94  \n",
       "20                            \n",
       "21                            \n",
       "22                            \n",
       "23                            "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 23,\n",
       "  'region': {'x': 71,\n",
       "   'y': 73,\n",
       "   'w': 112,\n",
       "   'h': 112,\n",
       "   'left_eye': (148, 114),\n",
       "   'right_eye': (101, 114)},\n",
       "  'face_confidence': 0.93,\n",
       "  'gender': {'Woman': 0.01159001185442321, 'Man': 99.98841285705566},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': 2.8227467089891434,\n",
       "   'indian': 2.5958621874451637,\n",
       "   'black': 1.0798390954732895,\n",
       "   'white': 43.30441355705261,\n",
       "   'middle eastern': 17.093738913536072,\n",
       "   'latino hispanic': 33.103397488594055},\n",
       "  'dominant_race': 'white',\n",
       "  'emotion': {'angry': 0.005496654485302767,\n",
       "   'disgust': 3.883063225289378e-11,\n",
       "   'fear': 0.013510097206376906,\n",
       "   'happy': 0.0001434568674114221,\n",
       "   'sad': 0.03585218355439556,\n",
       "   'surprise': 0.00042637821560333167,\n",
       "   'neutral': 99.94457363421603},\n",
       "  'dominant_emotion': 'neutral'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial_recognition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
